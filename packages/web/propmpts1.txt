this seems improving: sounds seem to be playing along with their corresponding group, but:

the spreading of group timestamps seems not yet normalised by default

----------




can you add logging so i can verify that the sequence elements are always evenly spread out, when adding more items to the sequence and removing them? also good to see the offset information and how it affects the timing

-----------


Great!

I'm wondering if we can add a twist: if one selects any of UI element groups for the sounds in the sequence, which would result in that group to become highlighted, then when clicking to add a sound, it is added to the same position in time, so then two sounds play at the same time at that time step, so effectively creating a kind of a sub-group of sounds at that timestep?

during the updates, please take care not to corrupt the currently working implementation for each time-step, just adding that grouping functionality, so more than one sound can play at the same time, using the current triggering functionality for each time step

----------


improving, but:

when removing sounds the proportional offsets don't seem to update correctly
when removing all groups but the first one, then adding a new sound, creating a second group, it is not heard in the sequence


------------


pretty good, but in some cases a sound's offset slider can be set to a non-zero value, even though i havent dragged it.



--------- 


when removing sounds from the sequece, so that there are fewer sound groups, the sounds do not play to their full duration, but seem clamped by previous sectioning, as when there were more sound groups: each sound should play to its full duration, regardless of the number of sounds / sound groups added or removed from the sequence


------


the UI looks nice, but:

i'm not able to adjust the sliders within each sound, within each trajectory: i can't drag a Pitch slider etc.

this is printed in the console on each slider-drag attempt:

Uncaught TypeError: this.stopTrajectoryPlayback is not a function
    at TrajectoryUnit.updateTrajectoryEvent (TrajectoryUnit.js:531:12)
    at onUpdate (UnitsPanel.jsx:361:44)
    at onChange (UnitsPanel.jsx:241:26)
    at onChange (UnitsPanel.jsx:24:24)


this is possible for the SequencingUnit elements: are we employing the same approach? - is the issue due to the trajectory sound elements being nested deeper?

still not able to drag the trajectory element sliders and on each attempt, this is printed in the console:

Uncaught TypeError: this.stopTrajectoryPlayback is not a function
    at TrajectoryUnit.updateTrajectoryEvent (TrajectoryUnit.js:531:12)
    at onUpdate (UnitsPanel.jsx:378:46)
    at onChange (UnitsPanel.jsx:257:26)
    at onChange (UnitsPanel.jsx:29:9)





now i observe changes when dragging Pitch and Stretch sliders for trajectory items, but actually regarding el.mc.sample we should only consider those parameters:
startOffsetstart: "Offset in samples from the start of the sample where playback starts"
stopOffset: "Offset in samples from the end of the sample where playback ends"
playbackRate: "Set below 1.0 to slow (and pitch) down, above 1.0 to speed (and pitch) up"
- but also keep the current offset slider to adjust the relative position of the sound element within the sequence


(i hope those calculations are comparable to what is already done for sequencing items), but i don't observe any changes when changing the Duration and Offset sliders

--------------


i can only drag the trajectory element sliders one step at a time, while i can drag the SequencingUnit elements sliders freely

can the slider behaviour for tajectory element sliders be made the same as it is for sequence element sliders?

currently i can only drag the trajectory element sliders one step at a time, while i can drag the sequence elment sliders freely

-------------


a TrajectoryUnit created after initialisation does not show the "(S)art Recording Trajectory" button until a node in the tree is hovered.
can you fix this without introducing a bug where stopping the recording of a trajectory associated with a second TrajectoryUnit does not result in it starting playing automaticall, as it currently does: we want to retain that functionality


-------


if i have two trajectory units, both playing back one trajectory recording, and i hit x to delete the first unit, its trajectory is still heard playing, while the playback in the second unit, which i did not select to remove, has been removed

it's like the (x) button to delete a unit is not deleting the correct unit?

the unit (x) ui element is perhaps not associated with the correct unit to delete the correct unit?

could log statements related to unit deltion actions help identify the problem?


----------------


now both trjacetory and sequence units have a way of adjusting the pitch of individual sequence/trajectory elements; sequencing unit has a pitch shift slider and trajectory unit has a playback rate slider:

in the UnitConfigPanel for both types, I would like to add a Pitch slider which in a way overrides the individual sequence / trajectory element pitch settings, so all the element sliders are set accordingly. That slider could be placed under a (collapsible) Playback section in the UnitConfigPanel (the SequencingUnit already has that section).

In the case of TrajectoryUnits, where the elements do not have a direct pitch shift setting, but a Playback Rate setting, it would be good to adjust the playback rate to a value equivalent to the selected pitch

----------

the global pitch slider now works for the SequencingUnit, but doesn't have an effect on the playback of recorded trajectories in the TrajectoryUnit

the global pitch slider should adjust all playback rate sliders for the trajectory elements, similarly to how it does now adjust the pitch sliders for SequencingUnit elements, but in the case of trajectory elements, adjusting the playback rate sliders in tandem acoording to the conversion from pitch to playback rate

the playback rate sliders of the trajectory elements now move in tandem with the trajectory-unit-global pitch slider, but now audible effect is heard: probably something is missing in applying the playback rate to the trajectory voices?

would it help how the movement of individual trajectory element sliders is handled: dragging those audibly changes the pitch, but when dragging the global pitch slider, the trajectory element sliders move but their output is not observed

the global pitch slider should adjust all playback rate sliders for the trajectory elements, similarly to how it does now adjust the pitch sliders for SequencingUnit elements, but in the case of trajectory elements, adjusting the playback rate sliders in tandem acoording to the conversion from pitch to playback rate

--------

the unit enable / disable and solo buttons seem to work, but (most often) only come into effect after dragging a units volume button, so it seems such an event is required to apply the effect of enabling / disabling or soling a unit

-------------



currently when hovering nodes in PhylogeneticViewer, when having a TrajectoryUnit active, the corresponding sound is played back, either one-off or looping: can we change the behaviour so that sounds are only played, added to a looping state or a trajectory, if the option/alt key or space bar are being pressed, to avoid accidental playbacks and trajectory additions when moving the mouse, making the sound events more deliberate?

-------------

currently when a trajectory is recorded with a TrajectoryUnit enabled, a UI group is presented for each trajectory recording in UnitsPanel. Can a similar UI group be created to represent the sounds that are currently a part of the set of looping voices, which are added when hovering nodes with the Looping mode enabled? - it would be good to have similar controls available for each looping sound, as are currently offered for elements of a trajectory recording, and have the possibility to stop all and remove all; if removed, the looping sounds UI group re-appears when a new (first) looping sound is added

it would be good if the individual loop elements would be collapsed under the main ui group heading, similar to how the trajectory ui group is configured
it would also be good if each looping element would have (collapsible) parameter controls as trajectory elements have


stopping individual loops seems to remove them instead of stopping them

--------------

when adding looping sounds, they have starting points at the time of addition, which can result in a nice polyrhytmic effect. but in other cases it could be good to have them start in tandem, at the same time: could this be an option in the UnitConfigPanel, beneath the "Looping" button, perhaps a radio button, "Sync Start" ? but also, it could be good to be able to change this after loop voices have been added, in the newly created UI group for looping voices; to be able to toggle between sync / async looping behaviour. this would probably entail recording the time of when a loop was added, so if "Sync Start" was enabled when loop voices were added, then it would still be possible to switch back to async more in the loop voices UI group in UnitsPanel (which is the current behaviour)

the UI looks good but i don't observe looping voices in tandem when "Sync Start" is enabled: could it be a matter of letting all looping voices follow the first voice when "Sync Start" is enabled?

-------

it seems to depend rather on when i change the position sliders rather than their absolute values, what phase offset is observed between different loops:

changing the sliders to their original positions does not necessarily result in the original phase between the looping voices


--------

The TrajectoryUnit has sliders for (master) pitch and maxVoices, which also affected looping voices, when looping voices were part of TrajectoryUnit: now that they have been moved to their own LoopingUnit, there should also be a pitch slider for LoopingUnit in the UnitConfigPanel, which overrides individual looping voices playback rate, as was the case when they were a part of TrjectoryUnit; and the voice updates should be as smooth / realtime as is the case for TrajectoryUnit.

and there should be a slider for max voices as well, where LoopingUnit should respect the maxVoices as TrajectoryUnit does.

--------

when switching between instances of units, they play seemingly ghost voice events, e.g. when switching to a TrajectoryUnit, it plays the last hovered sound, even though no node was hovered again (and there is no trajectory playback going on), and when switching to a Looping Unit, it plays one looping voice even though all looping voices had been removed from it before switching focus to another unit:

each unit instance should retain its state, regardless of wheter it is the focused unit or not: it should keep playing its voices when focus is switched from it, or keep not playing any voices, if that is the state when switching from it, so it should not suddently start playing a voice when gaining focus again, it should just keep playing or not playing whatever it was configured to do, whether it is focused or not


....

now i don't see the hover log events when switching to e.g. a TrajectoryUnit instance, but still it plays a phantom sound on becoming active, and there is this in the logs on sound having ended:

Sound ended: {nodeId: '01JE182R28ZSD58N93C7QFJJA7', isHovered: false, isLooping: true}



when switching between units in UnitsPanel, to a TrajectoryUnit to make it active, there seems to be triggered a cell hover event, even i just chose another unit to make it active

the logs show the following when just performing that unit switch, and a redundant sound is played:

CellDataFormatter input: {data: {…}, experiment: 'evoConf_singleMap_refSingleEmb_mfcc-sans0-statisti…_pca_retrainIncr50_zScoreNSynthTrain_noveltyArchv', evoRunId: '01JDZ9JTBP3DQB3WZNJJSQH7ZH_evoConf_singleMap_refSi…_pca_retrainIncr50_zScoreNSynthTrain_noveltyArchv', config: {…}}
UnitsPanel.jsx:188

-------

the units TrajectoryUnit, LoopingUnit and LoopingUnit represent their voices in UnitsPanel with slider controls associated with each voice: now i would like an additional parameter section for each voice (for all units, so hopefully some reused code): the new section should be called "Render" and contain sliders for Duration, Pitch and Velocity; the existing sliders could be grouped under a section titled "Modify"

those groups of sliders appear under a collapsible Parameters UI control: let's take extra care not to break the current expand / collapse functionality; previous attempts at this have resulted in the expandable section immideatly collapsing a gain on interaction such as dragging a slider

...

the Playback Rate sliders for SequencingUnit voices don't have any effect, and don't follow changes of the master slider in the UnitConfigPanel: the behaviour should be the same as for LoopingUnit voices:

when dragging per voice slider for a SequencingUnit, that voice's pitch / playback rate should be changed, and when changing the master pitch slider in the UnitConfigPanel, it should override the settings of all SequenceUnit voices, just as is currently done for LoopingUnit voices

-----------

when using the TrajectoryUnit to record a trajectory, individual trajectory recording voices have their parameter slider section. when hovering nodes, with a TrajectoryUnit active, without being in trajectory-recording mode, the hovered node is played back: could we add a UI group for the last hovered sound with the same settings as for the voices in a recorded trajectory, so there will be sibling UI groups: Trajectory groups for all recorded trajectories, like we have now, and "Explore" with the same parameter sliders (reused) as for trajectory-recording sounds; adjusting the sliders within the "Explore" section affects the hovered sounds (when not in recording mode).

let's make sure to keep performant playback of hovered sounds, e.g. when rapidling "strumming" a node, we want to hear the playback effect in fast realtime, so let's not break that with unnecessary book-keeping.

also, the position slider is not applicable in the "Explore" context


-----


now each voice in all units (with UI controls in UnitsPanel) - trajectory, recordings and explore one-offs, looping and sequene voices - has a set of parameter sliders grouped to Modify and Render groups: now i would like to start working on implementing the voice parameter sliders in the Render group (for the voices associated to all Unit types, so hopefully reusing functionality for all voice types):

Dragging each of the sliders in the Render group - Duration, Pitch and Velocity - should eventualy call a web socket service for re-rendering the corresponding sound with those three chosen parameters. To start with, let's scaffold a method / methods that will eventuall call out to the web service, but for now, just use the current audio buffer as a placeholder, but register it as a new entry in the elementary virtual file system (VFS), keyed with the same key plus values indicating those render setting changes (duration, pitch, velocity)

the duration slider in the Render section should also reflect the sound's current duration, e.g. if the current buffer is 4 seconds, the slider should be set at that value by default. The (scaffold / dummy) rendering service / function should not be called if a sound with those settings is already in the VFS; then the sound matching the parameter settings is just used from that storage. 

it would be good if the dummy functionality would take a fixed amount of time, to simulate the time a service call may eventually take, e.g. one second, and to have a visual indication while it's in progress, e.g. a spinner over the corresponding slider group.

-------

in the UnitConfigPanel, within the Sampler tab, there is the Envolope section with ADSR sliders. Can you enable those sliders so they set the envelope for for the voices in the active unit, handling all three unit types we have, with default settings so the envelope is completely open, so there is perceivably no envelope applied, as is (should) currently be the case.

here's the relevant Elementary documentation:

el.adsr(a, d, s, r, g) An exponential ADSR envelope generator, triggered by the gate signal g. When the gate is high (1), this generates the ADS phase. When the gate is low, the R phase.

Expected children:

Attack time in seconds (number or signal) Decay time in seconds (number or signal) Sustain amplitude between 0 and 1 (number or signal) Release time in seconds (number or signal) Gate signal; a pulse train alternating between 0 and 1

the ADSR needs a key, like other voice elements, so it can be properly re-targetted during slider updates in a smooth manner


-------------


so if i play a single sound from SequencingUnit, it is much louder than that same single sound played through TrajectoryUnit or LoopingUnit

is there some basic, fundamental difference in the setting of gain values in SequencingUnit?


------------


now we have different implementations of phylogenetic tree rendering, using either Canvas (in PhylogeneticViewer.jsx) or SVG (in PhylogeneticViewerSVG.jsx): the former wa built on the latter to obtain the more performant rendering: but there might be cases where one would like still to have access to the SVG rendering, e.g. for aesthetics or downloading the SVG. The implementations should share a lot of common implementation code and i'm wondering if the shared code could be extracted to a base class or component?



----------


now the all lines are completely straigh in the tree rendered in PhylogeneticViewer.jsx

if the connect nodes at an angle, e.g. not between nodes along a straight line, e.g. when a node has children, could the lines be curved as bézier curve, so exiting the node initially along a straigh line then curving towards the next node and curving into that node to eventually enter it at a straight angle?

----------

now i would like to improve touch screen interaction a bit: one e.g. a smartphone it is possible to tap the nodes to have them play, but i'd also like to be able to swipe over the nodes, in a similar manner as i can drage the mouse on a desktop to hover multiple nodes: on touch screens the drag gesture pans the view. i'm wondering if it would make sense to reserve two-finger drag for panning, allowing single finger swipe to hover nodes in a similar manner to how nodes are hovered with a desktop mouse?

...

If we focus on all the voice letters for a while, they seem a bit hard to drag. You can only drag the slider one step at a time before some action starts or you can click into a certain place on this letter. It would be nicer to be able to track the slider freely and when you stop tracking the action at the current value. Takes place.

---------

The TrajectoryUnit UI as an Explore section where duration etc. can be defined: could the other units, SequencingUnit and LoopingUnit have a corresponding section, where the render parameters would affect the sounds added as a looping voice or a sequence voice?

--------

the TrajectoryUnit UI has an Explore section: that UI section is not displayed until a first node is hovered, the it is displayed in the unit's UI in UnitsPanel: could it be visible from the start?

--------

when i change the render section sliders for a SequencingUnit voice, e.g. Duration, the new rendering result is not audible until i hover a node in the tree, so it seems the hover event triggers some necessary state transitions so that the new render version of the voice becomes audible, while it should become audible when the results have been returned from the rendering service, without further UI interaction.

can the new rendering application be automatic, somehow automatically performing the necessary actions that occur when hovering a node?

for instance i see this printed in the log when hovering:

SequencingUnit.js:419 Updating sequencer: {unitId: 1741280754507, isPlaying: true, sequenceLength: 1}

could that be a call that is required after a new rendering of a voice comes in?

and can we do this without trying to call functions that do not exist?

-------------

when switching between runs (results from evolutionary runs) with the large drop down menu at the top, unit settings (trajectory etc.) are lost: after switching the currently playing sounds are heard until sounds are added from the new view / dataset / run, then those take completely over:

can unit voices and their settings survive a switch to a new dataset, so that one can continue adding sounds and working with what has already been set up, from the new dataset. that is, can all settings be robust to view and dataset changes?

could it be a solution to somehow persist the state of all units, for example all the settings of a TrajectoryUnit instance, it's trajectories, their voices, the settings of the voices etc., so all state would be robust to view switches, even page reloads?

-------


for each SequencingUnit voice, it is possible to click to select it in UnitsPanel ("Click to Select / Deselect"), and when the voice is in selected mode, new voices get added to the same (time) step, in a way creating a chord at that step in the sequence: can we add a probability slider to the Evolution section in UnitConfigPanel, which is in effect when a new voice is added via evolution and dictates the probability of that voice being added to a random existing voice position, instead of being appended to the sequence, as currently is the default behaviour?
let's take care not to break existing sequence evolution functionality: if the sequence-step-grouping probability is at zero, then voices are just appended to the sequence as before (when Growing), but if the grouping probability is non-zero and we hit that case, a random existing voice-step is chosen and the new voice is placed at that time-step, given that we are adding a voice during evolution; in a similar mannar as one would have manually chosen "Click to Select" on a voice and manually clicked a node in the tree to add a corresponding voice at that timestep.


------


when playing a recorded trajectory from TrajectoryUnit, each voice plays to its end, even the trajectory has started again from the beginning, the last voice in the trajectory is allowed to play to its end when the first voice in the trajectory starts playing again and so on.

the situation is different for sequenced voices in SequencingUnit: when the sequence starts again from the beginning / loops, the last voice(es) is / are cut off, i.e. not allowed to play to their end, as the sequence loops, while it could be desirable to allow each voice to play to its end, even though the sequence is starting a new loop. can you identify what may cause that and how to enable all voices to play to their full duration, as trajectories in TrajectoryUnit allows?
could we retain the current behaviour while optionally have voice handling in SequencingUnit similar to TrajectoryUnit, in terms of allowing each voice play fully, not being cut off?